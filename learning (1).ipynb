{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjgiwq/3NbpXsBRlipGuTu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2tVXf8S3rof_"},"outputs":[],"source":["# **************************************************************************\n","# INF7370-Hiver 2024\n","# Travail pratique 1\n","# ===========================================================================\n","# ===========================================================================\n","# Indiquer votre nom ici\n","# ===========================================================================\n","# ===========================================================================\n","\n","# ===========================================================================\n","# Le but de ce travail est de classifier les restaurants en 2 états (Fermeture définitive / Ouvert)\n","#\n","# Ce fichier consiste la troisième étape du travail -> entrainement des modèles de classification\n","# Dans ce fichier code, vous devez entrainer 5 modèles de classification sur les données préparées dans l'étape précédente.\n","# ===========================================================================\n","\n","# ==========================================\n","# ======CHARGEMENT DES LIBRAIRIES===========\n","# ==========================================\n","\n","# la librairie principale pour la gestion des données\n","import pandas as pd\n","\n","# la librairie pour normalizer les données par Z-Score\n","from sklearn.preprocessing import StandardScaler\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","# - Inclure ici toutes les autres librairies dont vous aurez besoin\n","# - Écrivez en commentaire le rôle de chaque librairie\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","# les librairies pour la visualisation (courbes ROC et AUC)\n","import scikitplot as skplt\n","import matplotlib.pyplot as plt\n","\n","# la librairie pour diviser les données en ensembles d'entraînement et de test\n","from sklearn.model_selection import train_test_split\n","\n","# les librairies pour les modèles de classification\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# les librairies pour calculer diverses métriques d'évaluation des modèles\n","from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n","\n","# la librairie pour la sélection des caractéristiques basée sur le critère du gain d'information mutuel\n","from sklearn.feature_selection import SelectKBest, mutual_info_classif\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","\n","# ==========================================\n","# ===============VARIABLES==================\n","# ==========================================\n","\n","# l'emplacement des données sur le disque\n","# Note: Il faut placer le dossier \"donnees\"  contenant les 8 fichiers .csv dans le même endroit que les fichiers de code\n","data_path = \"donnees/\"\n","\n","# ==========================================\n","# ===============FONCTIONS==================\n","# ==========================================\n","\n","    # \"\"\"\n","    # La fonction entraîne plusieurs modèles sur un jeu de données donné et retourne une liste des modèles entraînés.\n","\n","    # :param models: Une liste de tuples, où chaque tuple contient le nom du modèle et l'objet modèle lui-même.\n","    # Par exemple, [(\"Modèle 1\", modele1), (\"Modèle 2\", modele2)]\n","    # :param x_train: Les données d'entraînement, qui consistent en les caractéristiques d'entrée utilisées pour entraîner les modèles.\n","    # C'est un objet de type matrice ou similaire avec la forme (n_samples, n_features), où n_samples est le nombre\n","    # d'échantillons dans les données d'entraînement et n_features est le nombre de caractéristiques d'entrée pour chaque échantillon.\n","    # :param y_train: Le paramètre y_train est la variable cible ou la variable dépendante. Elle représente la variable\n","    # que nous essayons de prédire ou de classifier.\n","    # :return: Une liste de tuples, où chaque tuple contient le nom d'un modèle et le modèle entraîné lui-même.\n","    # \"\"\"\n","def train_models(models, x_train, y_train):\n","    \"\"\"\n","    Entraîne une liste de modèles de classification donnée.\n","    :param models: Liste de tuples (nom_du_modèle, instance_du_modèle)\n","    :param x_train: Données d'entraînement\n","    :param y_train: Étiquettes d'entraînement\n","    :return: Liste de modèles entraînés\n","    \"\"\"\n","    trained_models = []\n","    for name, model in models:\n","        model.fit(x_train, y_train)\n","        trained_models.append((name, model))\n","    return trained_models\n","\n","    # \"\"\"\n","    # La fonction \"calculate_metrics\" calcule diverses métriques telles que le taux de vrais positifs (TP Rate),\n","    # le taux de faux positifs (FP Rate), la F-mesure et l'AUC pour évaluer la performance d'un modèle de classification binaire.\n","\n","    # :param y_test: Les étiquettes réelles de l'ensemble de test.\n","    # :param y_pred: Les étiquettes prédites pour l'ensemble de test.\n","    # :return: un dictionnaire contenant les métriques suivantes : TP Rate, FP Rate, F-mesure et AUC.\n","    # \"\"\"\n","def calculate_metrics(y_test, y_pred, y_probas):\n","    \"\"\"\n","    Calcule et retourne les métriques d'évaluation pour les prédictions données, en utilisant les probabilités pour l'AUC.\n","    :param y_test: Étiquettes réelles\n","    :param y_pred: Prédictions du modèle\n","    :param y_probas: Probabilités de la classe positive\n","    :return: Dictionnaire de métriques\n","    \"\"\"\n","    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","    metrics = {\n","        \"TP Rate\": tp / (tp + fn),\n","        \"FP Rate\": fp / (fp + tn),\n","        \"F-mesure\": f1_score(y_test, y_pred),\n","        \"AUC\": roc_auc_score(y_test, y_probas[:, 1])  # Utiliser les probabilités de la classe positive\n","    }\n","    return metrics\n","\n","    # \"\"\"\n","    # La fonction `evaluate_models` prend une liste de modèles entraînés, les données de test et les étiquettes de test, et évalue chaque modèle en calculant des métriques, en traçant des courbes ROC et en affichant des matrices de confusion.\n","\n","    # :param trained_models: Le paramètre \"trained_models\" est un dictionnaire ou une liste de modèles d'apprentissage automatique entraînés. Chaque modèle est associé à un nom ou identifiant unique.\n","    # :param x_test: Le paramètre `x_test` représente les caractéristiques d'entrée du jeu de données de test. C'est un objet matriciel ou similaire à un tableau avec la forme (n_samples, n_features), où n_samples est le nombre d'échantillons dans le jeu de données de test et n_features est le nombre de caractéristiques pour chaque échantillon.\n","    # :param y_test: Le paramètre `y_test` est les étiquettes réelles ou les valeurs cibles pour le jeu de données de test. Il est utilisé pour évaluer la performance des modèles entraînés en comparant les étiquettes prédites avec les étiquettes réelles.\n","    # \"\"\"\n","def evaluate_models(trained_models, x_test, y_test):\n","    \"\"\"\n","    Évalue les modèles entraînés et affiche les graphiques ROC et la matrice de confusion.\n","    \"\"\"\n","    for name, model in trained_models:\n","        y_probas = model.predict_proba(x_test)\n","        y_pred = model.predict(x_test)\n","\n","        metrics = calculate_metrics(y_test, y_pred, y_probas)\n","        print(f'Modèle: {name}')\n","        for metric_name, metric_value in metrics.items():\n","            print(f\"{metric_name}: {metric_value}\")\n","\n","        skplt.metrics.plot_roc(y_test, y_probas, plot_micro=False, plot_macro=False)\n","        plt.title(f'Courbe ROC - {name}')\n","        plt.show()\n","\n","        skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize=True)\n","        plt.title(f'Matrice de confusion - {name}')\n","        plt.show()\n","\n","        print('******************************\\n')\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","# - Inclure ici toutes les autres variables globales dont vous aurez besoin\n","# - Écrivez en commentaire le rôle de chaque variable\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","# Liste des modèles à entraîner\n","models = [\n","    (\"Arbre de décision\", DecisionTreeClassifier()),\n","    (\"Forêt aléatoire\", RandomForestClassifier()),\n","    (\"Naive Bayes\", GaussianNB()),\n","    (\"Bagging\", BaggingClassifier()),\n","    (\"AdaBoost\", AdaBoostClassifier())\n","]\n","\n","# ==========================================\n","# ====CHARGEMENT DES DONNÉES EN MÉMOIRE=====\n","# ==========================================\n","\n","# Charger en mémoire les features préparées dans la deuxième étape (pré-traités)\n","features = pd.read_csv(data_path + \"features_finaux.csv\")\n","\n","# ==========================================\n","# INITIALIZATION DES DONNÉES ET DES ÉTIQUETTES\n","# ==========================================\n","\n","# Initialisation des données et des étiquettes\n","x = features.copy() # \"x\" contient l'ensemble des données d'entrainement\n","y = x[\"ferme\"]      # \"y\" contient les étiquettes des enregistrements dans \"x\"\n","\n","# Elimination de la colonne classe (ferme) des features\n","x = x.drop('ferme', axis=1)\n","\n","# Sauvegardez les noms des colonnes de 'x' pour une utilisation ultérieure\n","feature_names = x.columns\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#                      QUESTION 1\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#  - Normaliser les données en utilisant Z-score (StandardScaler dans Scikit-learn)\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","sc = StandardScaler()\n","x = sc.fit_transform(x)\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#                      QUESTION 2\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","# - Divisez les données en deux lots (entrainement et test)\n","# (indiquer dans votre rapport le pourcentage des données de test que vous avez utilisé)\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#                      QUESTION 3\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","# - Entrainez 5 modèles de classification sur l'ensemble de données normalisées (avec tous les features)\n","#   1 - Arbre de decision\n","#   2 - Forêt d’arbres décisionnels (Random Forest)\n","#   3 - Classification bayésienne naïve\n","#   4 - Bagging\n","#   5 - AdaBoost\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","# Entraînement des modèles\n","trained_models = train_models(models, x_train, y_train)\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#                      QUESTION 4\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","# - Afficher les resultats sur les données test de chaque algorithm entrainé avec tous les features\n","#   1- Le taux des vrais positifs (TP Rate) – de la classe Restaurants fermés définitivement.\n","#   2- Le taux des faux positifs (FP Rate) – de la classe Restaurants fermés définitivement.\n","#   3- F-measure de la classe Restaurants fermés définitivement.\n","#   4- La surface sous la courbe ROC (AUC).\n","#   5- La matrice de confusion.\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","# Évaluation des modèles\n","evaluate_models(trained_models, x_test, y_test)\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#                      QUESTION 5\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","# - Selectionnez les tops 10 features\n","#\n","# Vous devez identifier les 10 meilleurs features en utilisant la mesure du Gain d’information (Mutual Info dans scikit-learn).\n","# Afficher les 10 meilleurs features dans un tableau (par ordre croissant selon le score obtenu par le Gain d'information).\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","# Sélection des 10 meilleurs features avec Mutual Information\n","selector = SelectKBest(mutual_info_classif, k=10)\n","x_selected = selector.fit_transform(x, y)\n","\n","# Récupération des scores pour chaque feature\n","feature_scores = selector.scores_\n","\n","# Création d'un DataFrame pour mieux visualiser les scores et les noms des features\n","feature_scores_df = pd.DataFrame({'Feature': feature_names, 'Score': feature_scores})\n","\n","# Trier les features selon leur score de Gain d'information\n","# Return the first n rows ordered by columns in descending order.\n","# This method is equivalent to df.sort_values(columns, ascending=False).head(n), but more performant.\n","# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nlargest.html\n","top_10_features = feature_scores_df.nlargest(10, 'Score')\n","\n","# Affichage des 10 meilleurs features\n","print(\"Les 10 meilleurs caractéristiques sélectionnés selon le Gain d'information sont :\")\n","print(top_10_features)\n","print(\"\\n\", \"-\"*80, \"\\n\")\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#                      QUESTION 6\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","# - Entrainez 5 modèles de classification sur l'ensemble de données normalisées avec seulement les top 10 features selectionnés.\n","#   1 - Arbre de decision\n","#   2 - Forêt d’arbres décisionnels (Random Forest)\n","#   3 - Classification bayésienne naïve\n","#   4 - Bagging\n","#   5 - AdaBoost\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","# Sélection des indices des 10 meilleurs caractéristiques pour la réduction des données\n","top_10_features_indices = selector.get_support(indices=True)\n","\n","# Création de nouveaux ensembles d'entraînement et de test avec seulement les 10 meilleurs caractéristiques\n","x_train_reduced = x_train[:, top_10_features_indices]\n","x_test_reduced = x_test[:, top_10_features_indices]\n","\n","# Réutilisation des fonctions pour entraîner et évaluer les modèles réduits\n","trained_models_reduced = train_models(models, x_train_reduced, y_train)\n","\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","#                      QUESTION 7\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","# - Afficher les resultats sur les données test de chaque algorithm entrainé avec les top 10 features\n","#   1- Le taux des vrais positifs (TP Rate) – de la classe Restaurants fermés définitivement.\n","#   2- Le taux des faux positifs (FP Rate) – de la classe Restaurants fermés définitivement.\n","#   3- F-measure de la classe Restaurants fermés définitivement.\n","#   4- La surface sous la courbe ROC (AUC).\n","#   5- La matrice de confusion.\n","# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\n","# Évaluation des modèles réduits\n","evaluate_models(trained_models_reduced, x_test_reduced, y_test)"]}]}